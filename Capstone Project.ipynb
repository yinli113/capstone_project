{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Title: Data Engineering Capstone Project\n",
    "\n",
    "### This script is part of a Data Engineering Capstone Project aimed at creating\n",
    "a data warehouse with fact and dimension tables for analysis and business intelligence.**\n",
    "\n",
    "#### The project encompasses the following steps:\n",
    "1. Scope the Project and Gather Data\n",
    "2. Explore and Assess the Data\n",
    "3. Define the Data Model\n",
    "4. Run ETL to Model the Data\n",
    "5. Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types as T\n",
    "from pyspark.sql.types import DateType, StructType, StructField, StringType, IntegerType, LongType, FloatType, DoubleType, TimestampType\n",
    "from pyspark.sql.functions import to_date, col, udf, unix_timestamp, year, month, lit, upper\n",
    "from pyspark.sql.functions import count, when, isnan\n",
    "from pyspark.sql.functions import monotonically_increasing_id, concat\n",
    "from pyspark.sql.functions import col, year, month, date_format\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "import os\n",
    "import configparser\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "This project investigates I94 immigration data and US demographic data to create a data warehouse with Fact and Dimension tables for analysis and business intelligence.( We assume the data is stored in AWS s3 bucket, and will be written back in s3 bucket. )\n",
    "\n",
    "Spark and Python are used to create the ETL pipeline , AWS S3 is uded to store the data and tables. The tables are designed to provide a comprehensive view of immigration events, combining individual immigration details with demographic information. The fact table is intended for analytical queries that need to explore immigration patterns, demographic trends, and the relationships between these elements(for example, the avergae population in certain year and certain state).\n",
    "\n",
    "The original sources of the data are all from Udacity, below is the link:\n",
    "1. [I94 Immigration Data](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "2. [Us Cities Demographics](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    "\n",
    "#### Describe and Gather Data \n",
    "##### I94 Immigration Data:\n",
    "1. This data comes from the US National Tourism and Trade Office. A data dictionary is included.[data_link_here](https://travel.trade.gov/research/reports/i94/historical/2016.html)\n",
    "2. This data is a SAS file, There's a sample file in csv format. Data contains over 20 columns including country code, arriving date, age, state, visa type ect.\n",
    "\n",
    "##### U.S. City Demographic Data:\n",
    "1. This data comes from OpenSoft. [data_link_here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)\n",
    "2. Thi data is a csv file. Data contains demographics of all US cities and with a population distribution and race number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immigration Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df_immi=pd.read_csv('immigration_data_sample.csv')\n",
    "df_immi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**US Cities Demographics Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "df_demo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration:\n",
    "\n",
    "- Start by working with a smaller subset of data, such as the immigration_data_sample.csv, to get a sense of its structure and contents.\n",
    "- Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data of immigration \n",
    "df_immi=pd.read_csv('immigration_data_sample.csv')\n",
    "df_immi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      "Unnamed: 0    1000 non-null int64\n",
      "cicid         1000 non-null float64\n",
      "i94yr         1000 non-null float64\n",
      "i94mon        1000 non-null float64\n",
      "i94cit        1000 non-null float64\n",
      "i94res        1000 non-null float64\n",
      "i94port       1000 non-null object\n",
      "arrdate       1000 non-null float64\n",
      "i94mode       1000 non-null float64\n",
      "i94addr       941 non-null object\n",
      "depdate       951 non-null float64\n",
      "i94bir        1000 non-null float64\n",
      "i94visa       1000 non-null float64\n",
      "count         1000 non-null float64\n",
      "dtadfile      1000 non-null int64\n",
      "visapost      382 non-null object\n",
      "occup         4 non-null object\n",
      "entdepa       1000 non-null object\n",
      "entdepd       954 non-null object\n",
      "entdepu       0 non-null float64\n",
      "matflag       954 non-null object\n",
      "biryear       1000 non-null float64\n",
      "dtaddto       1000 non-null object\n",
      "gender        859 non-null object\n",
      "insnum        35 non-null float64\n",
      "airline       967 non-null object\n",
      "admnum        1000 non-null float64\n",
      "fltno         992 non-null object\n",
      "visatype      1000 non-null object\n",
      "dtypes: float64(15), int64(2), object(12)\n",
      "memory usage: 226.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_immi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data of demographics\n",
    "df_demo = pd.read_csv('us-cities-demographics.csv', delimiter=';')\n",
    "df_demo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_demo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cic_id</th>\n",
       "      <th>country_code_1</th>\n",
       "      <th>country_code_2</th>\n",
       "      <th>city_code</th>\n",
       "      <th>arrive_date</th>\n",
       "      <th>state_code</th>\n",
       "      <th>depart_date</th>\n",
       "      <th>visa_code</th>\n",
       "      <th>occupation</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4084316.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>F</td>\n",
       "      <td>JL</td>\n",
       "      <td>00782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4422636.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>M</td>\n",
       "      <td>*GA</td>\n",
       "      <td>XBLNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1195600.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>M</td>\n",
       "      <td>LH</td>\n",
       "      <td>00464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5291768.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>M</td>\n",
       "      <td>QR</td>\n",
       "      <td>00739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>985523.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cic_id  country_code_1  country_code_2 city_code  arrive_date  \\\n",
       "0  4084316.0           209.0           209.0       HHW      20566.0   \n",
       "1  4422636.0           582.0           582.0       MCA      20567.0   \n",
       "2  1195600.0           148.0           112.0       OGG      20551.0   \n",
       "3  5291768.0           297.0           297.0       LOS      20572.0   \n",
       "4   985523.0           111.0           111.0       CHM      20550.0   \n",
       "\n",
       "  state_code  depart_date  visa_code occupation  birth_year gender airline  \\\n",
       "0         HI      20573.0        2.0        NaN      1955.0      F      JL   \n",
       "1         TX      20568.0        2.0        NaN      1990.0      M     *GA   \n",
       "2         FL      20571.0        2.0        NaN      1940.0      M      LH   \n",
       "3         CA      20581.0        2.0        NaN      1991.0      M      QR   \n",
       "4         NY      20553.0        2.0        NaN      1997.0      F     NaN   \n",
       "\n",
       "  flight_number  \n",
       "0         00782  \n",
       "1         XBLNG  \n",
       "2         00464  \n",
       "3         00739  \n",
       "4          LAND  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting the columns that could be used to create dimension tables, and renaming the columns name for better understanding\n",
    "stage_immi = df_immi[['cicid',  'i94cit', 'i94res', 'i94port', \\\n",
    "                      'arrdate','i94addr', 'depdate', 'i94visa',\\\n",
    "                      'occup', 'biryear',\\\n",
    "                      'gender', 'airline',  'fltno']]\n",
    "\n",
    "stage_immi.columns = ['cic_id', 'country_code_1','country_code_2','city_code',\\\n",
    "                      'arrive_date','state_code', 'depart_date','visa_code',\\\n",
    "                      'occupation','birth_year',\\\n",
    "                      'gender','airline','flight_number']\n",
    "\n",
    "\n",
    "stage_immi.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore bigger data \n",
    "1. Identify data quality issues, like missing values, duplicate data, etc.\n",
    "2. Document steps necessary to clean the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the saprk setting\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "os.environ['AWS_ACCESS_KEY_ID']=config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']=config['AWS']['AWS_SECRET_ACCESS_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession.builder.\\\n",
    "    config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "    config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11,org.apache.hadoop:hadoop-aws:2.7.0\").\\\n",
    "    enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_immigration write completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Read in immigration data \n",
    "immigration_data = spark.read.format('com.github.saurfang.sas.spark').\\\n",
    "            load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "\n",
    "# Create a functoin to rename the columns' name\n",
    "rename_columns = lambda table, new_columns: table.select(\n",
    "    *[col(original).alias(new) for original, new in zip(table.columns, new_columns)])\n",
    "\n",
    "\n",
    "# extract columns to create immigration staging table\n",
    "stage_immigration = immigration_data.select('cicid',  'i94cit', 'i94res', 'i94port', \\\n",
    "                      'arrdate','i94addr', 'depdate', 'i94visa',\\\n",
    "                      'occup', 'biryear',\\\n",
    "                      'gender', 'airline',  'fltno').distinct()\n",
    "                \n",
    "    \n",
    "# rename the columns\n",
    "new_column_names = ['cic_id', 'country_code_1','country_code_2','city_code',\\\n",
    "                      'arrive_date','state_code', 'depart_date','visa_code',\\\n",
    "                      'occupation','birth_year',\\\n",
    "                      'gender','airline','flight_number']\n",
    "    \n",
    "stage_immigration = rename_columns(stage_immigration, new_column_names)\n",
    "                                  \n",
    "# Write stage_immigration table to parquet files partitioned by 'state_code'\n",
    "try:\n",
    "    stage_immigration.write.mode(\"overwrite\").partitionBy(\"state_code\")\\\n",
    "            .parquet(os.path.join(\"./final/\", \"stage_immigration\"))\n",
    "    print(\"stage_immigration write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing stage_immigration table: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- country_code_1: double (nullable = true)\n",
      " |-- country_code_2: double (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- arrive_date: double (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- depart_date: double (nullable = true)\n",
      " |-- visa_code: double (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stage_immigration.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage_demographics write completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Read in US demographics data\n",
    "stage_demographics=spark.read.csv('us-cities-demographics.csv', inferSchema=True, header=True, sep=';')\n",
    "\n",
    "# extract columns to create demographic staging table\n",
    "stage_demographics = stage_demographics.select('City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
    "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
    "       'Average Household Size', 'State Code', 'Race', 'Count').distinct()\n",
    "                    \n",
    "# rename the columns\n",
    "new_column_names = ['City', 'State', 'Median_Age', 'Male_Population', 'Female_Population',\n",
    "       'Total_Population', 'Number_of_Veterans', 'Foreign_born',\n",
    "       'Average_Household_Size', 'State_Code', 'Race', 'Count']\n",
    "    \n",
    "stage_demographics = rename_columns(stage_demographics, new_column_names)\n",
    "\n",
    "\n",
    "# Write stage_demographics table to parquet files partitioned by 'state_code'\n",
    "try:\n",
    "    stage_demographics.write.mode(\"overwrite\").partitionBy(\"state_code\")\\\n",
    "            .parquet(os.path.join(\"./final/\", \"stage_demographics\"))\n",
    "    print(\"stage_demographics write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing stage_demographics table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median_Age</th>\n",
       "      <th>Male_Population</th>\n",
       "      <th>Female_Population</th>\n",
       "      <th>Total_Population</th>\n",
       "      <th>Number_of_Veterans</th>\n",
       "      <th>Foreign_born</th>\n",
       "      <th>Average_Household_Size</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maple Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>38.6</td>\n",
       "      <td>31780.0</td>\n",
       "      <td>36601.0</td>\n",
       "      <td>68381</td>\n",
       "      <td>2943.0</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>MN</td>\n",
       "      <td>White</td>\n",
       "      <td>59683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concord</td>\n",
       "      <td>California</td>\n",
       "      <td>39.6</td>\n",
       "      <td>62310.0</td>\n",
       "      <td>66358.0</td>\n",
       "      <td>128668</td>\n",
       "      <td>6287.0</td>\n",
       "      <td>37428.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>92575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlands Ranch</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>39.6</td>\n",
       "      <td>49186.0</td>\n",
       "      <td>53281.0</td>\n",
       "      <td>102467</td>\n",
       "      <td>4840.0</td>\n",
       "      <td>8827.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CO</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asheville</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>37.9</td>\n",
       "      <td>42100.0</td>\n",
       "      <td>46407.0</td>\n",
       "      <td>88507</td>\n",
       "      <td>4973.0</td>\n",
       "      <td>6630.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NC</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Westland</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>39.9</td>\n",
       "      <td>37742.0</td>\n",
       "      <td>44253.0</td>\n",
       "      <td>81995</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>6429.0</td>\n",
       "      <td>2.41</td>\n",
       "      <td>MI</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>16422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City           State  Median_Age  Male_Population  \\\n",
       "0      Maple Grove       Minnesota        38.6          31780.0   \n",
       "1          Concord      California        39.6          62310.0   \n",
       "2  Highlands Ranch        Colorado        39.6          49186.0   \n",
       "3        Asheville  North Carolina        37.9          42100.0   \n",
       "4         Westland        Michigan        39.9          37742.0   \n",
       "\n",
       "   Female_Population  Total_Population  Number_of_Veterans  Foreign_born  \\\n",
       "0            36601.0             68381              2943.0        7645.0   \n",
       "1            66358.0            128668              6287.0       37428.0   \n",
       "2            53281.0            102467              4840.0        8827.0   \n",
       "3            46407.0             88507              4973.0        6630.0   \n",
       "4            44253.0             81995              4756.0        6429.0   \n",
       "\n",
       "   Average_Household_Size State_Code                               Race  Count  \n",
       "0                    2.64         MN                              White  59683  \n",
       "1                    2.72         CA                              White  92575  \n",
       "2                    2.72         CO                              Asian   5650  \n",
       "3                    2.18         NC  American Indian and Alaska Native    496  \n",
       "4                    2.41         MI          Black or African-American  16422  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage_demographics.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning NULL values that could cause skewness of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+--------------+---------+-----------+-----------------+---------------+---------+-----------------+--------------------+------------------+-----------------+------------------+\n",
      "|cic_id|country_code_1|country_code_2|city_code|arrive_date|       state_code|    depart_date|visa_code|       occupation|          birth_year|            gender|          airline|     flight_number|\n",
      "+------+--------------+--------------+---------+-----------+-----------------+---------------+---------+-----------------+--------------------+------------------+-----------------+------------------+\n",
      "|   0.0|           0.0|           0.0|      0.0|        0.0|4.928183940060324|4.6008591508675|      0.0|99.73755883206898|0.025901774142342845|13.379429017673601|2.700857439154246|0.6313638188387285|\n",
      "+------+--------------+--------------+---------+-----------+-----------------+---------------+---------+-----------------+--------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the null percentage in each column of stage_immigration\n",
    "\n",
    "test_immigration = stage_immigration.select([\n",
    "    (count(when(isnan(c) | col(c).isNull(), c)) * 100 / stage_immigration.count()).alias(c)\n",
    "    for c in stage_immigration.columns\n",
    "])\n",
    "\n",
    "test_immigration.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cic_id: double, country_code_1: double, country_code_2: double, city_code: string, arrive_date: double, state_code: string, depart_date: double, visa_code: double, birth_year: double, gender: string, airline: string, flight_number: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# occupation's null percentage is too high , need to drop:\n",
    "stage_immigration.drop('occupation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+-------------------+-------------------+----------------+-------------------+-------------------+----------------------+----------+----+-----+\n",
      "|City|State|Median_Age|    Male_Population|  Female_Population|Total_Population| Number_of_Veterans|       Foreign_born|Average_Household_Size|State_Code|Race|Count|\n",
      "+----+-----+----------+-------------------+-------------------+----------------+-------------------+-------------------+----------------------+----------+----+-----+\n",
      "| 0.0|  0.0|       0.0|0.10377032168799723|0.10377032168799723|             0.0|0.44967139398132133|0.44967139398132133|    0.5534417156693185|       0.0| 0.0|  0.0|\n",
      "+----+-----+----------+-------------------+-------------------+----------------+-------------------+-------------------+----------------------+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the null percentage in each column of stage_demographics\n",
    "test_demographics = stage_demographics.select([\n",
    "    (count(when(isnan(c) | col(c).isNull(), c))*100/stage_demographics.count()).alias(c)\n",
    "    for c in stage_demographics.columns\n",
    "])\n",
    "\n",
    "test_demographics.show()\n",
    "# Result shows the percentage of null value is low and even in each column of table stage_demographics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As Star Schema can map multidimensional data structures in relational databases and is used primarily in Data Warehouses and OLAP apps and for BI, I will create a fact table as the center, various dimension tables are grouped around, creating the whole star schema.**\n",
    "\n",
    "### Fact Table\n",
    "\n",
    "#### immi_demographics\n",
    "- cic_id: double\n",
    "- country_code_1\n",
    "- country_code_2\n",
    "- city_code\n",
    "- arrive_date\n",
    "- immigration_state_code\n",
    "- depart_date\n",
    "- visa_code\n",
    "- birth_year\n",
    "- gender\n",
    "- airline\n",
    "- flight_number\n",
    "- avg_Median_Age\n",
    "- avg_Male_Population\n",
    "- avg_Female_Population\n",
    "- avg_Total_Population\n",
    "- avg_Number_of_Veterans\n",
    "- avg_Foreign_born\n",
    "- demographics_state_code\n",
    "- Race\n",
    "- year\n",
    "- month\n",
    "\n",
    "### Dimension Tables\n",
    "\n",
    "#### 1. dim_immi_personel\n",
    "- cic_id\n",
    "- country_code_1\n",
    "- country_code_2\n",
    "- birth_year\n",
    "- gender\n",
    "\n",
    "#### 2. dim_immi_airline\n",
    "- travel_id\n",
    "- city_code  \n",
    "- airline\n",
    "- flight_number\n",
    "- visa_code\n",
    "\n",
    "#### 3. dim_arrive_calendar\n",
    "- arrive_date\n",
    "- year\n",
    "- month\n",
    "- week\n",
    "- day\n",
    "\n",
    "#### 4. dim_depart_calendar\n",
    "- depart_date\n",
    "- year\n",
    "- month\n",
    "- week\n",
    "- day\n",
    "\n",
    "#### 5. demo_population_dim\n",
    "- demo_pop_id\n",
    "- State\n",
    "- Median_Age\n",
    "- Male_Population\n",
    "- Female_Population\n",
    "- Total_Population\n",
    "- Foreign_born\n",
    "- State_Code\n",
    "- Race"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The pipeline steps are described below:\n",
    "\n",
    "##### 1. Load raw datasources and form the staging tables: stage_immigration and stage_demographics.\n",
    "- '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' contains I94 Immigration datasource.\n",
    "- 'us-cities-demographics.csv' contains US Cities Demographics datasource.\n",
    "\n",
    "##### 2. Describe DataFrame structure:\n",
    "-  Pandas dataframe for small datasource exploration purpose, for example, undstand the column name, data type,ect.\n",
    "- Spark dataframe for bigger datasource exploration.\n",
    "\n",
    "##### 3. Clean the dataframe:\n",
    "- rename the columns' name for better understanding.\n",
    "- drop the columns with high percentage null values.\n",
    "\n",
    "##### 4. Transform staging tables to fact and dimemsion tables and write Spark DataFrame to the Parquet file.\n",
    "- immi_demographics (fact_table)\n",
    "- dim_immi_personel\n",
    "- dim_immi_airline\n",
    "- dim_arrive_calendar\n",
    "- dim_depart_calendar\n",
    "- demo_population_dim\n",
    "\n",
    "#### 5. Create data quality check for fact and dim tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_immi_personel write completed successfully\n"
     ]
    }
   ],
   "source": [
    "dim_immi_personel = (\n",
    "    stage_immigration\n",
    "    .select('cic_id', 'country_code_1', 'country_code_2', 'birth_year', 'gender')\n",
    "    .filter(col('cic_id').isNotNull())\n",
    "    .dropDuplicates(['cic_id'])\n",
    ")\n",
    "# Write dim_immi_personel table to parquet files \n",
    "try:\n",
    "    stage_demographics.write.mode(\"overwrite\").parquet(os.path.join(\"./final/\", \"dim_immi_personel\"))\n",
    "    print(\"dim_immi_personel write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing dim_immi_personel table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_immi_airline write completed successfully\n"
     ]
    }
   ],
   "source": [
    "dim_immi_airline = stage_immigration.select(\n",
    "        concat(monotonically_increasing_id(), col('city_code')).alias('travel_id'),\n",
    "        col('city_code'),  \n",
    "        col('airline'),\n",
    "        col('flight_number'),\n",
    "        col('visa_code')\n",
    "    )\n",
    "# Write dim_immi_airline table to parquet files \n",
    "try:\n",
    "    stage_demographics.write.mode(\"overwrite\").parquet(os.path.join(\"./final/\", \"dim_immi_airline\"))\n",
    "    print(\"dim_immi_airline write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing dim_immi_airline table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def dateConvert(date):\n",
    "    \"\"\"\n",
    "    Convert an integer date to a datetime object.\n",
    "\n",
    "    This function takes an integer representing a date as the number of days \n",
    "    from a fixed point in time (January 1, 1960) and converts it into a \n",
    "    datetime object. If the input is None, the function returns None.\n",
    "\n",
    "    Args:\n",
    "        date (int or None): The date represented as an integer or None.\n",
    "\n",
    "    Returns:\n",
    "        datetime or None: The converted date as a datetime object, \n",
    "                          or None if the input is None.\n",
    "    \"\"\"\n",
    "    if date is not None:\n",
    "        # Convert the integer date to a Timestamp using a UDF\n",
    "        return datetime(1960, 1, 1) + timedelta(days=date)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Register the dateConvert function as a UDF\n",
    "dateConvertUDF = udf(dateConvert, TimestampType())\n",
    "\n",
    "# Use the UDF to convert the arrive_date and depart_date columns\n",
    "stage_immigration = stage_immigration.withColumn('arrive_date', dateConvertUDF(col('arrive_date')))\n",
    "stage_immigration = stage_immigration.withColumn('depart_date', dateConvertUDF(col('depart_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_arrive_calendar write completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Extract year, month, week, and day from arrive_date using PySpark functions\n",
    "\n",
    "# Remove duplicates from the original DataFrame\n",
    "stage_immigration = stage_immigration.dropDuplicates([\"arrive_date\"])\n",
    "\n",
    "# Extract year, month, week, and day from depart_date using PySpark functions\n",
    "dim_arrive_calendar = stage_immigration.select(\n",
    "    \"arrive_date\",\n",
    "    year(\"arrive_date\").alias(\"year\"),\n",
    "    month(\"arrive_date\").alias(\"month\"),\n",
    "    date_format(\"arrive_date\", \"w\").alias(\"week\"),\n",
    "    date_format(\"arrive_date\", \"d\").alias(\"day\")\n",
    ")\n",
    "\n",
    "# Writing the DataFrame to parquet format with partitioning\n",
    "output_path = os.path.join(\"./final/\", \"dim_arrive_calendar\")\n",
    "try:\n",
    "    dim_arrive_calendar.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(output_path)\n",
    "    print(\"dim_arrive_calendar write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing dim_arrive_calendar table: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_depart_calendar write completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Extract year, month, week, and day from depart_date using PySpark functions\n",
    "\n",
    "# Remove duplicates from the original DataFrame\n",
    "stage_immigration = stage_immigration.dropDuplicates([\"depart_date\"])\n",
    "\n",
    "# Extract year, month, week, and day from depart_date using PySpark functions\n",
    "dim_depart_calendar = stage_immigration.select(\n",
    "    \"depart_date\",\n",
    "    year(\"depart_date\").alias(\"year\"),\n",
    "    month(\"depart_date\").alias(\"month\"),\n",
    "    date_format(\"depart_date\", \"w\").alias(\"week\"),\n",
    "    date_format(\"depart_date\", \"d\").alias(\"day\")\n",
    ")\n",
    "\n",
    "# Writing the DataFrame to parquet format with partitioning\n",
    "output_path = os.path.join(\"./final/\", \"dim_depart_calendar\")\n",
    "try:\n",
    "    dim_depart_calendar.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(output_path)\n",
    "    print(\"dim_depart_calendar write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing dim_depart_calendar table: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_population_dim write completed successfully\n"
     ]
    }
   ],
   "source": [
    "demo_population_dim = (\n",
    "    stage_demographics\n",
    "    .select(\n",
    "        monotonically_increasing_id().alias('demo_pop_id'),\n",
    "        col('State'),\n",
    "        col('Median_Age'),\n",
    "        col('Male_Population'),\n",
    "        col('Female_Population'),\n",
    "        col('Total_Population'), \n",
    "        col('Foreign_born'),\n",
    "        col('State_Code'),\n",
    "        col('Race')\n",
    "    )\n",
    "    .dropDuplicates(['demo_pop_id'])\n",
    ")\n",
    "\n",
    "# Write demo_population_dim table to parquet files \n",
    "try:\n",
    "    demo_population_dim.write.mode(\"overwrite\").parquet(os.path.join(\"./final/\", \"demo_population_dim\"))\n",
    "    print(\"demo_population_dim write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing demo_population_dim table: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- country_code_1: double (nullable = true)\n",
      " |-- country_code_2: double (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- arrive_date: timestamp (nullable = true)\n",
      " |-- immigration_state_code: string (nullable = true)\n",
      " |-- depart_date: timestamp (nullable = true)\n",
      " |-- visa_code: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- avg_Median_Age: double (nullable = true)\n",
      " |-- avg_Male_Population: double (nullable = true)\n",
      " |-- avg_Female_Population: double (nullable = true)\n",
      " |-- avg_Total_Population: double (nullable = true)\n",
      " |-- avg_Number_of_Veterans: double (nullable = true)\n",
      " |-- avg_Foreign_born: double (nullable = true)\n",
      " |-- demographics_state_code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "immi_demographics write completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Creating temporary tables \n",
    "stage_demographics.createOrReplaceTempView(\"temp_demographics\")\n",
    "stage_immigration.createOrReplaceTempView(\"temp_immigration\")\n",
    "\n",
    "'''\n",
    "creating the fact table immi_demographics in the provided code is to consolidate\n",
    "and combine relevant information from two source tables, temp_immigration and \n",
    "temp_demographics, into a single table that can be used for analytical purposes.\n",
    "The code performs inner join between temp_immigration and an aggregated version\n",
    "of temp_demographics. The join is based on the state_code column, connecting immigration\n",
    "data with demographic data.\n",
    "\n",
    "'''\n",
    "immi_demographics = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        ti.cic_id, \n",
    "        ti.country_code_1,\n",
    "        ti.country_code_2,\n",
    "        ti.city_code,\n",
    "        ti.arrive_date,\n",
    "        ti.state_code AS immigration_state_code,\n",
    "        ti.depart_date,\n",
    "        ti.visa_code,\n",
    "        ti.birth_year,\n",
    "        ti.gender,\n",
    "        ti.airline,\n",
    "        ti.flight_number,\n",
    "        AVG(td.Median_Age) as avg_Median_Age,\n",
    "        AVG(td.Male_Population) as avg_Male_Population,\n",
    "        AVG(td.Female_Population) as avg_Female_Population,\n",
    "        AVG(td.Total_Population) as avg_Total_Population,\n",
    "        AVG(td.Number_of_Veterans) as avg_Number_of_Veterans,\n",
    "        AVG(td.Foreign_born) as avg_Foreign_born,\n",
    "        td.State_Code AS demographics_state_code,  \n",
    "        td.Race,\n",
    "        YEAR(ti.arrive_date) as year,\n",
    "        MONTH(ti.arrive_date) as month \n",
    "    FROM temp_immigration ti\n",
    "    JOIN (\n",
    "        SELECT \n",
    "            State_Code,\n",
    "            AVG(Median_Age) as Median_Age,\n",
    "            AVG(Male_Population) as Male_Population,\n",
    "            AVG(Female_Population) as Female_Population,\n",
    "            AVG(Total_Population) as Total_Population,\n",
    "            AVG(Number_of_Veterans) as Number_of_Veterans,\n",
    "            AVG(Foreign_born) as Foreign_born,\n",
    "            MAX(State) as State,\n",
    "            MAX(Race) as Race\n",
    "        FROM temp_demographics\n",
    "        GROUP BY State_Code\n",
    "    ) td ON ti.state_code = td.State_Code\n",
    "    GROUP BY \n",
    "        ti.cic_id, \n",
    "        ti.country_code_1,\n",
    "        ti.country_code_2,\n",
    "        ti.city_code,\n",
    "        ti.arrive_date,\n",
    "        ti.state_code, \n",
    "        ti.depart_date,\n",
    "        ti.visa_code,\n",
    "        ti.birth_year,\n",
    "        ti.gender,\n",
    "        ti.airline,\n",
    "        ti.flight_number,\n",
    "        td.State_Code,\n",
    "        td.Race,\n",
    "        YEAR(ti.arrive_date),\n",
    "        MONTH(ti.arrive_date)\n",
    "\"\"\")\n",
    "\n",
    "immi_demographics.printSchema()\n",
    "\n",
    "try:\n",
    "    immi_demographics.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(os.path.join(\"./final/\", \"immi_demographics\"))\n",
    "    print(\"immi_demographics write completed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing immi_demographics table: {str(e)}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- country_code_1: double (nullable = true)\n",
      " |-- country_code_2: double (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- arrive_date: timestamp (nullable = true)\n",
      " |-- immigration_state_code: string (nullable = true)\n",
      " |-- depart_date: timestamp (nullable = true)\n",
      " |-- visa_code: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- avg_Median_Age: double (nullable = true)\n",
      " |-- avg_Male_Population: double (nullable = true)\n",
      " |-- avg_Female_Population: double (nullable = true)\n",
      " |-- avg_Total_Population: double (nullable = true)\n",
      " |-- avg_Number_of_Veterans: double (nullable = true)\n",
      " |-- avg_Foreign_born: double (nullable = true)\n",
      " |-- demographics_state_code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immi_demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: double (nullable = true)\n",
      " |-- country_code_1: double (nullable = true)\n",
      " |-- country_code_2: double (nullable = true)\n",
      " |-- birth_year: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immi_personel.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- travel_id: string (nullable = true)\n",
      " |-- city_code: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight_number: string (nullable = true)\n",
      " |-- visa_code: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_immi_airline.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- arrive_date: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- week: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_arrive_calendar.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- depart_date: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- week: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_depart_calendar.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- demo_pop_id: long (nullable = false)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median_Age: double (nullable = true)\n",
      " |-- Male_Population: integer (nullable = true)\n",
      " |-- Female_Population: integer (nullable = true)\n",
      " |-- Total_Population: integer (nullable = true)\n",
      " |-- Foreign_born: integer (nullable = true)\n",
      " |-- State_Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_population_dim.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating temporary sql tables for data quality checks\n",
    "dim_immi_personel.createOrReplaceTempView(\"dim_immi_personel\")\n",
    "dim_immi_airline.createOrReplaceTempView(\"dim_immi_airline\")\n",
    "dim_arrive_calendar.createOrReplaceTempView(\"dim_arrive_calendar\")\n",
    "dim_depart_calendar.createOrReplaceTempView(\"dim_depart_calendar\")\n",
    "demo_population_dim.createOrReplaceTempView(\"demo_population_dim\")\n",
    "immi_demographics.createOrReplaceTempView(\"immi_demographics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Count checks to ensure completeness and integrity constraints (primary key, merging condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+-------------+\n",
      "|count(1)|count(DISTINCT cic_id)|count(cic_id)|\n",
      "+--------+----------------------+-------------+\n",
      "| 3096313|               3096313|      3096313|\n",
      "+--------+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "count(*)\n",
    ", count(distinct cic_id)\n",
    ", count(cic_id)\n",
    "from dim_immi_personel\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------------+----------------+\n",
      "|count(1)|count(DISTINCT travel_id)|count(travel_id)|\n",
      "+--------+-------------------------+----------------+\n",
      "| 3096313|                  3096313|         3096313|\n",
      "+--------+-------------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "count(*)\n",
    ", count(distinct travel_id)\n",
    ", count(travel_id)\n",
    "from dim_immi_airline\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------+------------------+\n",
      "|count(1)|count(DISTINCT arrive_date)|count(arrive_date)|\n",
      "+--------+---------------------------+------------------+\n",
      "|      30|                         30|                30|\n",
      "+--------+---------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "count(*)\n",
    ", count(distinct arrive_date)\n",
    ", count(arrive_date)\n",
    "from dim_arrive_calendar\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------+------------------+\n",
      "|count(1)|count(DISTINCT depart_date)|count(depart_date)|\n",
      "+--------+---------------------------+------------------+\n",
      "|      22|                         21|                21|\n",
      "+--------+---------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "count(*)\n",
    ", count(distinct depart_date)\n",
    ", count(depart_date)\n",
    "from dim_depart_calendar\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------+------------------+\n",
      "|count(1)|count(DISTINCT demo_pop_id)|count(demo_pop_id)|\n",
      "+--------+---------------------------+------------------+\n",
      "|    2891|                       2891|              2891|\n",
      "+--------+---------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "select \n",
    "count(*)\n",
    ", count(distinct demo_pop_id)\n",
    ", count(demo_pop_id)\n",
    "from demo_population_dim\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------+------------------------------+\n",
      "|total_rows|count(immigration_state_code)|count(demographics_state_code)|\n",
      "+----------+-----------------------------+------------------------------+\n",
      "|        21|                           21|                            21|\n",
      "+----------+-----------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) AS total_rows,\n",
    "        COUNT( immigration_state_code),\n",
    "        COUNT( demographics_state_code)\n",
    "    FROM immi_demographics\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Further investigation on dim_depart_calendar:\n",
    "**The count of unique depart_date values is less than the total count suggests that there are duplicate depart_date values in the DataFrame. To investigate further and identify the duplicates, run the following Spark SQL query:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|depart_date|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if depart_date is unique in dim_deaprt_calendar\n",
    "spark.sql(\"\"\"\n",
    "SELECT depart_date, COUNT(*) AS count\n",
    "FROM dim_depart_calendar\n",
    "GROUP BY depart_date\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY count DESC\n",
    "\"\"\").show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|depart_date|\n",
      "+-----------+\n",
      "|       null|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if depart_date has missing value\n",
    "spark.sql(\"\"\"\n",
    "SELECT depart_date\n",
    "FROM dim_depart_calendar\n",
    "WHERE depart_date IS NULL OR depart_date = ''\n",
    "\"\"\").show()                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result explain:\n",
    "- The result indicates that there is only one row in dp_calendar DataFrame where the depart_date column is null. There are no rows where the depart_date column is an empty string ('').\n",
    "\n",
    "- In order to  handle this null value, I will remove the row with the null value. Here's how to drop the row with a null value:\n",
    "```dp_calendar = dp_calendar.filter(dp_calendar[\"depart_date\"].isNotNull())```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Schema validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the schema validation\n",
    "expected_schema = [\"cic_id\", \"country_code_1\", \"country_code_2\", \"birth_year\", \"gender\"]\n",
    "\n",
    "sql_queries = [f\"SELECT * FROM dim_immi_personel WHERE `{col}` IS NULL\" for col in expected_schema]\n",
    "null_check_queries = \" UNION ALL \".join(sql_queries)\n",
    "\n",
    "mismatch_df = spark.sql(null_check_queries)\n",
    "\n",
    "if mismatch_df.count() > 0:\n",
    "    print(\"Schema mismatch!\")\n",
    "else:\n",
    "    print(\"Schema is valid.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The \"Schema mismatch\" error suggests that there is a mismatch between the expected schema and the actual schema of the dim_immi_personel table. To identify the issues, further investigation include :\n",
    "1. Check if dim_immi_personel Exists.\n",
    "2. Verify Data Types\n",
    "3. Check for Missing Columns.\n",
    "4. Check for NULL Values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file. -- please check Data_Dictionary.PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Tools and technologies for the project\n",
    "- AWS s3 : used for storaging and loading data and tables.\n",
    "- Pandas : used for small data exploration for data structure understanding\n",
    "- Apache Spark : used for larger data processing, including extracting, transformating and loading data warehouse tables.\n",
    "\n",
    "#### 5.2 Frequency of Data Updates\n",
    "Given that the fact table immi_demographics is derived from immigration and demographics data, the update frequency largely depends on how often the underlying data changes. Here are some considerations:\n",
    "\n",
    "- Immigration Data: If this data changes frequently (daily or weekly), fact table should be updated at the same frequency to ensure it reflects the most current trends and patterns.\n",
    "- Demographic Data: Demographic data doesn't change as rapidly. Updating it annually or semi-annually might be sufficient.\n",
    "\n",
    "#### 5.3 Approach for Different Scenarios\n",
    "##### a. Data Volume Increases by 100x\n",
    "* Scaling Infrastructure: Utilize a more powerful cluster with additional nodes to handle the increased data volume in Spark.\n",
    "* Optimize Data Storage: Use efficient file formats like Parquet, which is already in use, and consider partitioning and bucketing strategies to improve query performance.\n",
    "* Caching: For frequently accessed data, consider caching tables or specific queries in Spark.\n",
    "* Resource Management: Fine-tune resource allocation (e.g., memory, cores) to ensure efficient processing.\n",
    "* Archiving: Archive older data that's accessed less frequently to maintain system performance.\n",
    "\n",
    "##### b. Daily Dashboard Updates by 7 am\n",
    "* Workflow Scheduling: Use a workflow scheduler like Apache Airflow to manage the ETL pipeline, ensuring data is processed and ready before the 7 am deadline.\n",
    "* Incremental Loading: Instead of processing the entire dataset each day, use incremental loading techniques to process only new or changed data.\n",
    "* Monitoring and Alerts: Implement monitoring for the ETL process to quickly identify and resolve any issues that could delay the daily update.\n",
    "\n",
    "##### c. Database Accessed by 100+ People\n",
    "* Concurrency and Load Management: Use a database that can handle high concurrency, ensuring multiple users can query the data simultaneously without performance degradation.\n",
    "* Access Controls: Implement role-based access controls to manage who can view or modify the data.\n",
    "* Scalability: Ensure the underlying infrastructure can scale to support multiple users. This might involve scaling up the database or using a distributed database system.\n",
    "* Caching Popular Queries: Cache results of common queries to improve response times.\n",
    "* Usage Monitoring: Monitor database usage to identify bottlenecks and optimize performance where needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
